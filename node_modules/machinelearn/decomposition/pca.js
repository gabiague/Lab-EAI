"use strict";
var __read = (this && this.__read) || function (o, n) {
    var m = typeof Symbol === "function" && o[Symbol.iterator];
    if (!m) return o;
    var i = m.call(o), r, ar = [], e;
    try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);
    }
    catch (error) { e = { error: error }; }
    finally {
        try {
            if (r && !r.done && (m = i["return"])) m.call(i);
        }
        finally { if (e) throw e.error; }
    }
    return ar;
};
var __spread = (this && this.__spread) || function () {
    for (var ar = [], i = 0; i < arguments.length; i++) ar = ar.concat(__read(arguments[i]));
    return ar;
};
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];
    result["default"] = mod;
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
var tf = __importStar(require("@tensorflow/tfjs"));
var numeric = __importStar(require("numeric"));
var ops_1 = require("../ops");
/**
 * Principal component analysis (PCA)
 *
 * Linear dimensionality reduction using Singular Value Decomposition of
 * the data to project it to a lower dimensional space.
 *
 * - It uses the LAPACK implementation of the full SVD
 * - or randomized a randomised truncated SVD by the method of
 * Halko et al. 2009, depending on the shape
 * of the input data and the number of components to extract. (Will be implemented)
 *
 * @example
 * import { PCA } from 'machinelearn/decomposition';
 *
 * const pca = new PCA();
 * const X = [[1, 2], [3, 4], [5, 6]];
 * pca.fit(X);
 * console.log(pca.components); // result: [ [ 0.7071067811865476, 0.7071067811865474 ], [ 0.7071067811865474, -0.7071067811865476 ] ]
 * console.log(pca.explained_variance); // result: [ [ -0.3535533905932736, 0 ], [ 0, 0.5 ], [ 0.35355339059327373, 0 ] ]
 */
var PCA = /** @class */ (function () {
    function PCA() {
    }
    /**
     * Fit the model with X.
     * At the moment it does not take n_components into consideration
     * so it will only calculate Singular value decomposition
     * @param {any} X
     */
    PCA.prototype.fit = function (X) {
        ops_1.validateMatrix2D(X);
        ops_1.validateMatrixType(X, ['number']);
        var nSamples = X.length;
        // Renaming X to A for readability
        var A = tf.tensor2d(X);
        // const transposed = tf.transpose(A, [1, 0]);
        var AT = tf.transpose(A, [1, 0]);
        var M = tf.mean(AT, 1);
        var rawC = tf.sub(A, M);
        var C = ops_1.reshape(__spread(rawC.dataSync()), rawC.shape);
        var svd = numeric.svd(C);
        this.components = svd.V;
        this.explained_variance = numeric.div(numeric.pow(svd.U), nSamples - 1);
    };
    /**
     * Predict does nothing in PCA
     * @param X - A 2D matrix
     */
    PCA.prototype.predict = function (X) {
        if (X === void 0) { X = null; }
        console.info('Predict does nothing in PCA\n', X);
        return null;
    };
    /**
     * Saves the model's states
     */
    PCA.prototype.toJSON = function () {
        return {
            components: this.components,
            explained_variance: this.explained_variance
        };
    };
    /**
     * Restores the model from given states
     * @param components - Principal axes in feature space, representing the directions of maximum variance in the data.
     * @param explained_variance - The amount of variance explained by each of the selected components.
     */
    PCA.prototype.fromJSON = function (_a) {
        var _b = _a === void 0 ? {
            components: null,
            explained_variance: null
        } : _a, _c = _b.components, components = _c === void 0 ? null : _c, _d = _b.explained_variance, explained_variance = _d === void 0 ? null : _d;
        this.components = components;
        this.explained_variance = explained_variance;
    };
    return PCA;
}());
exports.PCA = PCA;
//# sourceMappingURL=data:application/json;base64,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