import { IMlModel, Type1DMatrix, Type2DMatrix } from '../types';
export declare type Type = 'C_SVC' | 'NU_SVC' | 'ONE_CLASS' | 'EPSILON_SVR' | 'NU_SVR';
export declare type Kernel = 'LINEAR' | 'POLYNOMIAL' | 'RBF' | 'SIGMOID';
/**
 * Options used by sub classes
 * Notice type is disabled as they are set statically from children classes
 */
export interface SVMOptions {
    /**
     * Degree of polynomial, test for polynomial kernel
     */
    degree?: number;
    /**
     * Type of Kernel
     */
    kernel?: Kernel;
    /**
     * Gamma parameter of the RBF, Polynomial and Sigmoid kernels. Default value is 1/num_features
     */
    gamma?: number | null;
    /**
     * coef0 parameter for Polynomial and Sigmoid kernels
     */
    coef0?: number;
    /**
     * Cost parameter, for C SVC, Epsilon SVR and NU SVR
     */
    cost?: number;
    /**
     * For NU SVC and NU SVR
     */
    nu?: number;
    /**
     * For epsilon SVR
     */
    epsilon?: number;
    /**
     * Cache size in MB
     */
    cacheSize?: number;
    /**
     * Tolerance
     */
    tolerance?: number;
    /**
     * Use shrinking euristics (faster)
     */
    shrinking?: boolean;
    /**
     * weather to train SVC/SVR model for probability estimates,
     */
    probabilityEstimates?: boolean;
    /**
     * Set weight for each possible class
     */
    weight?: object | null;
    /**
     * Print info during training if false (aka verbose)
     */
    quiet?: boolean;
}
/**
 * BaseSVM class used by all parent SVM classes that are based on libsvm
 */
export declare class BaseSVM implements IMlModel<number> {
    protected svm: any;
    protected type: Type;
    protected options: SVMOptions;
    constructor(options?: SVMOptions);
    /**
     * Fit the model according to the given training data.
     * @param {number[][]} X
     * @param {number[]} y
     * @returns {Promise<void>}
     */
    fit(X: Type2DMatrix<number>, y: Type1DMatrix<number>): Promise<void>;
    /**
     * Predict using the linear model
     * @param {number[][]} X
     * @returns {number[]}
     */
    predict(X: Type2DMatrix<number>): number[];
    /**
     * Predict the label of one sample.
     * @param {number[]} X
     * @returns {number}
     */
    predictOne(X: Type1DMatrix<number>): number[];
    /**
     * Saves the current SVM as a JSON object
     * @returns {{svm: any; type: Type; options: SVMOptions}}
     */
    toJSON(): {
        svm: any;
        type: Type;
        options: SVMOptions;
    };
    /**
     * Restores the model from a JSON checkpoint
     * @param {any} svm
     * @param {any} type
     * @param {any} options
     */
    fromJSON({ svm, type, options }: {
        svm?: any;
        type?: any;
        options?: any;
    }): void;
    /**
     * Load SVM object by resolving the default promise
     * @returns {Promise<any>}
     */
    private loadSVM;
    /**
     * Get Kernel name type using string Kernel name
     * @param SVM
     * @param {string} name
     * @returns {number}
     */
    private getKernel;
    /**
     * Get Kernel type using string type name
     * @param SVM
     * @param {string} name
     * @returns {number}
     */
    private getType;
    /**
     * Get a consolidated options including type and Kernel
     * @param SVM
     * @param {Options} options
     * @param {Type} type
     * @param {Kernel} kernel
     * @returns {Object}
     */
    private processOptions;
}
/**
 * C-Support Vector Classification.
 *
 * The implementation is based on libsvm. The fit time complexity is more than
 * quadratic with the number of samples which makes it hard to scale to dataset
 * with more than a couple of 10000 samples.
 *
 * The multiclass support is handled according to a one-vs-one scheme.
 *
 * For details on the precise mathematical formulation of the provided kernel
 * functions and how gamma, coef0 and degree affect each other, see the corresponding
 * section in the narrative documentation: Kernel functions.
 */
export declare class SVC extends BaseSVM {
    constructor(options?: SVMOptions);
}
/**
 * Linear Support Vector Regression.
 *
 * Similar to SVR with parameter kernel=’linear’, but implemented in terms of
 * liblinear rather than libsvm, so it has more flexibility in the choice of
 * penalties and loss functions and should scale better to large numbers of samples.
 *
 * This class supports both dense and sparse input.
 */
export declare class SVR extends BaseSVM {
    constructor(options?: SVMOptions);
}
/**
 * Unsupervised Outlier Detection.
 *
 * Estimate the support of a high-dimensional distribution.
 *
 * The implementation is based on libsvm.
 */
export declare class OneClassSVM extends BaseSVM {
    constructor(options?: SVMOptions);
}
/**
 * Nu-Support Vector Classification.
 *
 * Similar to SVC but uses a parameter to control the number of support vectors.
 *
 * The implementation is based on libsvm.
 */
export declare class NuSVC extends BaseSVM {
    constructor(options?: SVMOptions);
}
/**
 * Nu Support Vector Regression.
 *
 * Similar to NuSVC, for regression, uses a parameter nu to control the number
 * of support vectors. However, unlike NuSVC, where nu replaces C, here nu
 * replaces the parameter epsilon of epsilon-SVR.
 *
 * The implementation is based on libsvm.
 */
export declare class NuSVR extends BaseSVM {
    constructor(options?: SVMOptions);
}
