import * as tf from '@tensorflow/tfjs';
import { countBy, isEmpty, zip } from 'lodash';
import { reshape, validateFitInputs, validateMatrix2D } from '../ops';
/**
 * Multinomial naive bayes machine learning algorithm
 *
 * The Naive is an intuitive method that uses probabilistic of each attribute
 * being in each class to make a prediction. It uses multinomial function to estimate
 * probability of a given class.
 *
 * @example
 * import { MultinomialNB } from 'machinelearn/naive_bayes';
 *
 * const nb = new MultinomialNB();
 * const X = [[1, 20], [2, 21], [3, 22], [4, 22]];
 * const y = [1, 0, 1, 0];
 * nb.fit({ X, y });
 * nb.predict({ X: [[1, 20]] }); // returns [ 1 ]
 *
 */
export class MultinomialNB {
    constructor() {
        this.alpha = 1;
    }
    // constructor(private readonly alpha: number = 1) {}
    /**
     * Fit date to build Gaussian Distribution summary
     *
     * @param  {Type2DMatrix<number>} X - training values
     * @param  {ReadonlyArray<T>} y - target values
     * @returns void
     */
    fit(X = null, y = null) {
        validateFitInputs(X, y);
        const { classCategories, multinomialDist, priorProbability } = this.fitModel(X, y);
        this.classCategories = classCategories;
        this.multinomialDist = multinomialDist;
        this.priorProbability = priorProbability;
    }
    /**
     * Predict multiple rows
     *
     * @param  {Type2DMatrix<number>} X - values to predict in Matrix format
     * @returns T
     */
    predict(X = null) {
        validateMatrix2D(X);
        if (isEmpty(this.classCategories) ||
            isEmpty(this.multinomialDist) ||
            isEmpty(this.priorProbability)) {
            throw new TypeError('You should fit the model first before running the predict!');
        }
        return X.map(x => this.singlePredict(x));
    }
    /**
     * Returns a model checkpoint
     *
     * @returns InterfaceFitModelAsArray
     */
    toJSON() {
        return {
            classCategories: Array.from(this.classCategories),
            priorProbability: Array.from(this.priorProbability.dataSync()),
            multinomialDist: reshape(Array.from(this.multinomialDist.dataSync()), this.multinomialDist.shape)
        };
    }
    /**
     * Restore the model from states
     * @param multinomialDist - Multinomial distribution values over classes
     * @param priorProbability - Learned prior class probabilities
     * @param classCategories - List of unique class categories
     */
    fromJSON({ multinomialDist = null, priorProbability = null, classCategories = null } = {
        multinomialDist: null,
        priorProbability: null,
        classCategories: null
    }) {
        this.classCategories = classCategories;
        this.priorProbability = tf.tensor1d(priorProbability);
        this.multinomialDist = tf.tensor2d(multinomialDist);
    }
    /**
     * Make a prediction
     *
     * @param  {ReadonlyArray<number>} predictRow
     * @returns T
     */
    singlePredict(predictRow) {
        const matrixX = tf.tensor1d(predictRow, 'float32');
        const numFeatures = matrixX.shape[0];
        const summaryLength = this.multinomialDist.shape[1];
        // Comparing input and summary shapes
        if (numFeatures !== summaryLength) {
            throw new Error(`Prediction input ${matrixX.shape[0]} length must be equal or less than summary length ${summaryLength}`);
        }
        // log is important to use different multinomial formula instead of the factorial formula
        // The multinomial naive Bayes classifier becomes a linear
        // classifier when expressed in log-space
        // const priorProbability = Math.log(1 / classCount);
        const fitProbabilites = this.multinomialDist
            .clone()
            .mul(matrixX);
        // sum(1) is summing columns
        const allProbabilities = fitProbabilites
            .sum(1)
            .add(this.priorProbability);
        const selectionIndex = allProbabilities.argMax().dataSync()[0];
        allProbabilities.dispose();
        return this.classCategories[selectionIndex];
    }
    /**
     * Summarise the dataset per class
     *
     * @param  {Type2DMatrix<number>} X - input distribution
     * @param  {ReadonlyArray<T>} y - classes to train
     */
    fitModel(X, y) {
        const classCounts = countBy(y);
        const classCategories = Array.from(new Set(y));
        const numFeatures = X[0].length;
        const separatedByCategory = zip(X, y).reduce((groups, [row, category]) => {
            if (!(category.toString() in groups)) {
                groups[category.toString()] = [];
            }
            groups[category.toString()].push(tf.tensor1d(row, 'float32'));
            return groups;
        }, {});
        const frequencySumByClass = tf.stack(classCategories.map((category) => tf.addN(separatedByCategory[category.toString()])));
        const productReducedRow = Array.from(frequencySumByClass.sum(1).dataSync());
        // A class's prior may be calculated by assuming equiprobable classes
        // (i.e., priors = (number of samples in the class) / (total number of samples))
        const priorProbability = tf
            .tensor1d(classCategories.map(c => classCounts[c.toString()] / y.length), 'float32')
            .log();
        // log transform to use linear multinomial forumla
        const multinomialDist = frequencySumByClass
            .add(tf.scalar(this.alpha))
            .div(tf
            .tensor2d(productReducedRow, [frequencySumByClass.shape[0], 1], 'float32')
            .add(tf.scalar(numFeatures * this.alpha)))
            .log();
        return {
            classCategories,
            multinomialDist,
            priorProbability
        };
    }
}
//# sourceMappingURL=data:application/json;base64,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