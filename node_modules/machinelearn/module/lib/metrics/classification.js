import * as tf from '@tensorflow/tfjs';
import * as _ from 'lodash';
import { reshape } from '../ops';
import { checkArray } from '../utils/validation';
/**
 * util function to calculate a weighted sum
 * @param {any} sampleScore
 * @param {any} normalize
 * @returns {number}
 * @ignore
 */
function _weightedSum({ sampleScore, 
// sampleWeight = null,
normalize = false }) {
    if (normalize) {
        return _.mean(sampleScore);
    }
    else {
        return _.sum(sampleScore);
    }
}
/**
 * Validator for classification exceptions
 * @param y_true
 * @param y_pred
 * @param labels
 * @param options
 * @ignore
 */
export const validateInitialInputs = (y_true, y_pred, labels, options = {}) => {
    const checkMultiClass = _.get(options, 'multiclass');
    // Multiclass
    if (checkMultiClass) {
        // TODO: Multi label
        if (checkArray(y_true).multiclass || checkArray(y_pred).multiclass) {
            throw new Error('Multiclass is not supported yet!');
        }
    }
    // Checking nullity or empty
    if (!y_true || _.isEmpty(y_true)) {
        throw new Error('y_true cannot be null or empty');
    }
    if (!y_pred || _.isEmpty(y_pred)) {
        throw new Error('y_pred cannot be null or empty');
    }
    // Checking the size equality
    if (_.size(y_true) !== _.size(y_pred)) {
        throw new Error('y_true and y_pred are not equal in size!');
    }
    // Checking labels equal to both y_true and y_pred classes
    // Labels is optional
    if (labels) {
        const yTrueCls = _.flowRight(x => _.sortBy(x, y => y), x => _.uniq(x))(y_true);
        const yPredCls = _.flowRight(x => _.sortBy(x, y => y), x => _.uniq(x))(y_pred);
        const sortedLabels = _.sortBy(labels, x => x);
        if (!_.isEqual(sortedLabels, yTrueCls) ||
            !_.isEqual(sortedLabels, yPredCls)) {
            throw new Error('Labels must match the classes');
        }
    }
};
/**
 * Accuracy classification score.
 *
 * In multilabel classification, this function computes subset accuracy:
 * the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.
 *
 * @example
 * import { accuracyScore } from 'machinelearn/metrics';
 *
 * const accResult = accuracyScore(
 *  [0, 1, 2, 3],
 *  [0, 2, 1, 3]
 * );
 *
 * // accuracy result: 0.5
 *
 * @param y_true - 1d array-like, or label indicator array / sparse matrix
 * @param y_pred - 1d array-like, or label indicator array / sparse matrix
 * @param normalize
 */
export function accuracyScore(y_true = null, y_pred = null, { normalize = true } = // sample_weight = null
 {
    normalize: true
}) {
    validateInitialInputs(y_true, y_pred, null, { multiclass: true });
    const yTrueRange = _.range(0, _.size(y_true));
    const normalised = _.map(yTrueRange, index => {
        const yTrue = y_true[index];
        const yPred = y_pred[index];
        return yTrue === yPred ? 1 : 0;
    });
    return _weightedSum({
        normalize,
        sampleScore: normalised
    });
}
/**
 * Zero-one classification loss.
 *
 * If normalize is `true`, return the fraction of misclassifications (float),
 * else it returns the number of misclassifications (int). The best performance is 0.
 *
 * @example
 * import { zeroOneLoss } from 'machinelearn/metrics';
 *
 * const loss_zero_one_result = zeroOneLoss(
 *   [1, 2, 3, 4],
 *   [2, 2, 3, 5]
 * );
 * console.log(loss_zero_one_result); // 0.5
 *
 * @param {any} y_true - Ground truth (correct) labels.
 * @param {any} y_pred - Predicted labels, as returned by a classifier.
 * @param {any} normalize
 * @returns {number}
 */
export function zeroOneLoss(y_true = null, y_pred = null, { 
/**
 * If False, return the number of misclassifications. Otherwise, return the fraction of misclassifications.
 */
normalize = true } = {
    normalize: true
}) {
    if (normalize) {
        return 1 - accuracyScore(y_true, y_pred);
    }
    // TODO: Fix return 0; implement when normalize === false
    return 0;
}
/**
 * A confusion matrix is a technique for summarizing the performance of a classification algorithm.
 *
 * Classification accuracy alone can be misleading if you have an unequal number of observations in each class or if you have more than two classes in your dataset.
 *
 * Calculating a confusion matrix can give you a better idea of what your classification model is getting right and what types of errors it is making.
 *
 * @example
 * import { confusion_matrix } from 'machinelearn/metrics';
 *
 * const matrix1 = confusion_matrix([1, 2, 3], [1, 2, 3]);
 * console.log(matrix1); // [ [ 1, 0, 0 ], [ 0, 1, 0 ], [ 0, 0, 1 ] ]
 *
 * const matrix2 = confusion_matrix(
 *   ['cat', 'ant', 'cat', 'cat', 'ant', 'bird'],
 *   ['ant', 'ant', 'cat', 'cat', 'ant', 'cat']
 * );
 * console.log(matrix2); // [ [ 1, 2, 0 ], [ 2, 0, 0 ], [ 0, 1, 0 ] ]
 *
 * @param y_true - Ground truth (correct) target values.
 * @param y_pred - Estimated targets as returned by a classifier.
 * @param labels
 */
export function confusion_matrix(y_true = null, y_pred = null, { 
/**
 * List of labels to index the matrix. This may be used to reorder or
 * select a subset of labels. If none is given, those that appear
 * at least once in y_true or y_pred are used in sorted order.
 */
labels = null } = {
    labels: null
}) {
    validateInitialInputs(y_true, y_pred, labels);
    // TODO: Sorting if set by options
    // TODO: classes should be based on yTrue
    const yTrueCls = _.uniqBy(y_true, x => x);
    const yPredCls = _.uniqBy(y_pred, x => x);
    // TODO: Issue was raisen to fix the typing: https://github.com/josdejong/mathjs/issues/1150
    const yTrueSize = _.size(yTrueCls);
    // const placeholder: any = math.zeros(_.size(yTrueCls), _.size(yTrueCls));
    const rawZeros = [...tf.zeros([yTrueSize, yTrueSize]).dataSync()];
    const placeholder = reshape(rawZeros, [yTrueSize, yTrueSize]);
    // Calculating the confusion matrix
    // Looping the index for y_true
    const rowRange = _.range(0, _.size(placeholder));
    _.forEach(rowRange, rowIndex => {
        // Looping the index for y_pred
        const colRange = _.range(0, _.size(placeholder[rowIndex]));
        _.forEach(colRange, colIndex => {
            // Get current target y true and y pred
            const yTargetTrueVal = yTrueCls[rowIndex];
            const yTargetPredVal = yPredCls[colIndex];
            // Looping the range of y true for pairing
            const yTrueRange = _.range(0, _.size(y_true));
            const score = _.reduce(yTrueRange, (sum, n) => {
                const trueVal = y_true[n];
                const predVal = y_pred[n];
                if (_.isEqual(trueVal, yTargetTrueVal) &&
                    _.isEqual(predVal, yTargetPredVal)) {
                    return sum + 1;
                }
                return sum;
            }, 0);
            // Recording the score
            placeholder[rowIndex][colIndex] = score;
        });
    });
    return placeholder;
}
//# sourceMappingURL=data:application/json;base64,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