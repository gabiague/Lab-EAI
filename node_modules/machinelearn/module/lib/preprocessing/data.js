import * as tf from '@tensorflow/tfjs';
import * as _ from 'lodash';
import { inferShape, reshape, validateMatrix1D, validateMatrix2D } from '../ops';
import math from '../utils/MathExtra';
import { combinationsWithReplacement } from '../utils/permutations';
/**
 * Augment dataset with an additional dummy feature.
 * This is useful for fitting an intercept term with implementations which cannot otherwise fit it directly.
 *
 * @example
 * import { add_dummy_feature } from 'machinelearn/preprocessing';
 * const dummy = add_dummy_feature([[0, 1, 2], [1, 0, 3]]);
 * console.log(dummy); // returns: [ [ 1, 0, 1, 2 ], [ 1, 1, 0, 3 ] ]
 *
 * @param X - A matrix of data
 * @param value - Value to use for the dummy feature.
 */
export function add_dummy_feature(X = null, value = 1.0) {
    if (Array.isArray(X) && X.length === 0) {
        throw new TypeError('X cannot be empty');
    }
    validateMatrix2D(X);
    const tensorX = tf.tensor2d(X);
    const [nSamples] = tensorX.shape;
    const ones = tf.ones([nSamples, 1]);
    const sValue = tf.scalar(value);
    const multipledOnes = tf.mul(ones, sValue);
    const hStacked = tf.concat([multipledOnes, tensorX], 1);
    return reshape(Array.from(hStacked.dataSync()), hStacked.shape);
}
/**
 * Encode categorical integer features using a one-hot aka one-of-K scheme.
 *
 * The input to this transformer should be a matrix of integers, denoting the
 * values taken on by categorical (discrete) features. The output will be a sparse
 * matrix where each column corresponds to one possible value of one feature.
 * It is assumed that input features take on values in the range [0, n_values).
 *
 * This encoding is needed for feeding categorical data to many
 * scikit-learn estimators, notably linear models and SVMs with the standard kernels.
 *
 * Note: a one-hot encoding of y labels should use a LabelBinarizer instead.
 *
 * @example
 * const enc = new OneHotEncoder();
 * const planetList = [
 *  { planet: 'mars', isGasGiant: false, value: 10 },
 *  { planet: 'saturn', isGasGiant: true, value: 20 },
 *  { planet: 'jupiter', isGasGiant: true, value: 30 }
 * ];
 * const encodeInfo = enc.encode(planetList, {
 *  dataKeys: ['value', 'isGasGiant'],
 *  labelKeys: ['planet']
 * });
 * // encodeInfo.data -> [ [ -1, 0, 1, 0, 0 ], [ 0, 1, 0, 1, 0 ], [ 1, 1, 0, 0, 1 ] ]
 * const decodedInfo = enc.decode(encodeInfo.data, encodeInfo.decoders);
 * // gives you back the original value, which is `planetList`
 */
export class OneHotEncoder {
    constructor() {
        /**
         * Calculating the sample standard deviation (vs population stddev).
         * @param lst
         * @param {number} mean
         * @returns {number}
         */
        this.calculateStd = (lst, mean) => {
            const deviations = _.map(lst, (n) => Math.pow(n - mean, 2));
            return Math.pow(_.sum(deviations) / (lst.length - 1), 0.5);
        };
    }
    /**
     * encode data according to dataKeys and labelKeys
     *
     * @param data - list of records to encode
     * @param options
     */
    encode(data = null, { 
    /**
     * Independent variables
     */
    dataKeys = null, 
    /**
     * Depdenent variables
     */
    labelKeys = null } = {
        dataKeys: null,
        labelKeys: null
    }) {
        const decoders = [];
        // shortcut to allow caller to default to "all non-label keys are data keys"
        const _dataKeys = dataKeys ? dataKeys : _.keys(data[0]);
        // validations
        if (_.size(data) < 1) {
            throw Error('data cannot be empty!');
        }
        // data keys
        _.forEach(_dataKeys, dataKey => {
            // TODO: it's only checking data[0] -> It should also check all the others
            if (!_.has(data[0], dataKey)) {
                // TODO: Find the correct error to throw
                throw Error(`Cannot find ${dataKey} from data`);
            }
        });
        // label keys
        _.forEach(labelKeys, labelKey => {
            // TODO: it's only checking data[0] -> It should also check all the others
            if (!_.has(data[0], labelKey)) {
                // TODO Find the correct error to throw
                throw Error(`Cannot find ${labelKey} from labels`);
            }
        });
        // maybe a little too clever but also the simplest;
        // serialize every value for a given data key, then zip the results back up into a (possibly nested) array
        const transform = (keys) => _.zip(..._.map(keys, (key) => {
            const standardized = this.standardizeField(key, data);
            const encoded = _.get(standardized, 'encoded');
            const decode = _.get(standardized, 'decode');
            if (encoded && decode) {
                // TODO: We need to prefer immutable datastructure
                decoders.push(decode);
                return encoded;
            }
            // Otherwise just return values itself
            return standardized;
        }));
        const features = transform(_dataKeys);
        const labels = transform(labelKeys);
        return {
            // zip the label data back into the feature data (to ensure label data is at the end)
            data: _.map(_.zip(features, labels), _.flattenDeep),
            decoders
        };
    }
    /**
     * Decode the encoded data back into its original format
     */
    decode(encoded, decoders) {
        return _.map(encoded, row => this.decodeRow(row, decoders));
    }
    /**
     * Decode an encoded row back into its original format
     * @param row
     * @param decoders
     * @returns {Object}
     */
    decodeRow(row, decoders) {
        let i = 0;
        let numFieldsDecoded = 0;
        const record = {};
        const getStrVal = (X, ix, decoder) => {
            const data = X.slice(ix, ix + decoder.offset);
            return decoder.lookupTable[_.indexOf(data, 1)];
        };
        const getBoolVal = (X, ix) => !!X[ix];
        const getNumbVal = (X, ix, decoder) => {
            return decoder.std * X[ix] + decoder.mean;
        };
        while (i < row.length) {
            const decoder = decoders[numFieldsDecoded++];
            if (decoder.type === 'string') {
                record[decoder.key] = getStrVal(row, i, decoder);
            }
            else if (decoder.type === 'number') {
                record[decoder.key] = getNumbVal(row, i, decoder);
            }
            else if (decoder.type === 'boolean') {
                record[decoder.key] = getBoolVal(row, i);
            }
            else {
                record[decoder.key] = row[i];
            }
            // record[decoder.key] = getValue(row, i, decoder);
            i += decoder.offset ? decoder.offset : 1;
        }
        return record;
    }
    /**
     * Standardizing field
     * Example dataset:
     * [ { planet: 'mars', isGasGiant: false, value: 10 },
     * { planet: 'saturn', isGasGiant: true, value: 20 },
     * { planet: 'jupiter', isGasGiant: true, value: 30 } ]
     *
     * @param key: each key/feature such as planet, isGasGiant and value
     * @param data: the entire dataset
     * @returns {any}
     */
    standardizeField(key, data) {
        const type = typeof data[0][key];
        const values = _.map(data, key);
        switch (type) {
            case 'string': {
                const result = this.buildStringOneHot(type, key, values);
                return {
                    decode: result.decode,
                    encoded: result.encoded
                };
            }
            case 'number': {
                // Apply std to values if type is number
                // standardize: ((n - mean)/std)
                // TODO: add support for scaling to [0, 1]
                const result = this.buildNumberOneHot(type, key, values);
                return {
                    decode: result.decode,
                    encoded: result.encoded
                };
            }
            case 'boolean': {
                // True == 1
                // False == 0
                const result = this.buildBooleanOneHot(type, key, values);
                return {
                    decode: result.decode,
                    encoded: result.encoded
                };
            }
            default:
                return values;
        }
    }
    /**
     * One hot encode a number value
     *
     * @param type
     * @param key
     * @param values
     * @returns {{encoded: any[]; decode: {type: any; mean: number; std: number; key: any}}}
     */
    buildNumberOneHot(type, key, values) {
        const mean = _.mean(values);
        const std = this.calculateStd(values, mean);
        return {
            decode: { type, mean, std, key },
            encoded: _.map(values, (value) => (value - mean) / std)
        };
    }
    /**
     * One hot encode a boolean value
     *
     * Example usage:
     * boolEncoder.encode(true) => 1
     * boolEncoder.encode(false) => 0
     *
     * @param type
     * @param key
     * @param values
     * @returns {{encode}}
     */
    buildBooleanOneHot(type, key, values) {
        return {
            decode: { type, key },
            encoded: _.map(values, value => (value ? 1 : 0))
        };
    }
    /**
     * One hot encode a string value
     *
     * Example for internal reference (unnecessary details for those just using this module)
     *
     * const encoder = buildOneHot(['RAIN', 'RAIN', 'SUN'])
     * // encoder == { encode: () => ... , lookupTable: ['RAIN', 'SUN'] }
     * encoder.encode('SUN')  // [0, 1]
     * encoder.encode('RAIN') // [1, 0]
     * encoder.encode('SUN')  // [1, 0]
     * // encoder.lookupTable can then be passed into this.decode to translate [0, 1] back into 'SUN'
     *
     * It's not ideal (ideally it would all just be done in-memory and we could return a "decode" closure,
     * but it needs to be serializable to plain old JSON.
     */
    buildStringOneHot(type, key, values) {
        const lookup = {};
        let i = 0;
        const lookupTable = _.map(_.uniq(values), (value) => {
            _.set(lookup, value, i++);
            return value;
        });
        const encoded = _.map(values, (value) => _.range(0, i).map(pos => (_.get(lookup, value) === pos ? 1 : 0)));
        return {
            decode: {
                key,
                lookupTable,
                offset: encoded[0].length,
                type
            },
            encoded
        };
    }
}
/**
 * Transforms features by scaling each feature to a given range.
 *
 * This estimator scales and translates each feature individually such that it is in the given range on the training set, i.e. between zero and one.
 *
 * The transformation is given by:
 *
 * ```
 * X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))
 * X_scaled = X_std * (max - min) + min
 * ```
 *
 * where min, max = feature_range.
 *
 * This transformation is often used as an alternative to zero mean, unit variance scaling.
 *
 * @example
 * import { MinMaxScaler } from 'machinelearn/preprocessing';
 *
 * const minmaxScaler = new MinMaxScaler({ featureRange: [0, 1] });
 *
 * // Fitting an 1D matrix
 * minmaxScaler.fit([4, 5, 6]);
 * const result = minmaxScaler.transform([4, 5, 6]);
 * // result = [ 0, 0.5, 1 ]
 *
 * // Fitting a 2D matrix
 * const minmaxScaler2 = new MinMaxScaler({ featureRange: [0, 1] });
 * minmaxScaler2.fit([[1, 2, 3], [4, 5, 6]]);
 * const result2 = minmaxScaler2.transform([[1, 2, 3]]);
 * // result2 = [ [ 0, 0.2, 0.4000000000000001 ] ]
 *
 */
export class MinMaxScaler {
    /**
     * @param featureRange - scaling range
     */
    constructor({ featureRange = [0, 1] } = {
        featureRange: [0, 1]
    }) {
        this.featureRange = featureRange;
    }
    /**
     * Compute the minimum and maximum to be used for later scaling.
     * @param {number[]} X - Array or sparse-matrix data input
     */
    fit(X = null) {
        let rowMax = tf.tensor(X);
        let rowMin = tf.tensor(X);
        const xShape = inferShape(X);
        // If input is a Matrix...
        if (xShape.length === 0 || xShape[0] === 0) {
            throw new TypeError('Cannot fit with an empty value');
        }
        else if (xShape.length === 2) {
            rowMax = tf.max(rowMax, 0);
            rowMin = tf.min(rowMin, 0);
        }
        this.dataMax = tf.max(rowMax).dataSync()[0];
        this.dataMin = tf.min(rowMin).dataSync()[0];
        this.featureMax = this.featureRange[1];
        this.featureMin = this.featureRange[0];
        // const zz = zzdataMax - zzdataMin;
        this.dataRange = this.dataMax - this.dataMin;
        // We need different data range for multi-dimensional
        this.scale = (this.featureMax - this.featureMin) / this.dataRange;
        this.baseMin = this.featureMin - this.dataMin * this.scale;
    }
    /**
     * Fit to data, then transform it.
     * @param X - Original input vector
     */
    fit_transform(X) {
        this.fit(X);
        return this.transform(X);
    }
    /**
     * Scaling features of X according to feature_range.
     * @param X - Original input vector
     */
    transform(X = null) {
        // Transforms a single vector
        const transform_single = _X => {
            const X1 = _X.map(x => x * this.scale);
            return X1.map(x => x + this.baseMin);
        };
        const shapes = inferShape(X);
        if (shapes.length === 2) {
            return X.map(z => transform_single(z));
        }
        else if (shapes.length === 1) {
            return transform_single(X);
        }
        else {
            throw new TypeError(`The input shape ${JSON.stringify(shapes)} cannot be transformed`);
        }
    }
    /**
     * Undo the scaling of X according to feature_range.
     * @param {number[]} X - Scaled input vector
     */
    inverse_transform(X = null) {
        validateMatrix1D(X);
        const X1 = X.map(x => x - this.baseMin);
        return X1.map(x => x / this.scale);
    }
}
/**
 * Binarizer transform your data using a binary threshold.
 * All values above the threshold are marked 1 and all equal to or below are marked as 0.
 *
 * It can also be used as a pre-processing step for estimators that consider
 * boolean random variables (e.g. modelled using the Bernoulli distribution in
 * a Bayesian setting).
 *
 * @example
 * import { Binarizer } from 'machinelearn/preprocessing';
 *
 * const binX = [[1, -1, 2], [2, 0, 0], [0, 1, -1]];
 * const binarizer = new Binarizer({ threshold: 0 });
 * const result = binarizer.transform(binX);
 * // [ [ 1, 0, 1 ], [ 1, 0, 0 ], [ 0, 1, 0 ] ]
 */
export class Binarizer {
    /**
     *
     * @param {number} threshold - Feature values below or equal to this are replaced by 0, above it by 1.
     * @param {boolean} copy - Flag to clone the input value.
     */
    constructor({ 
    // Each object param default value
    copy = true, threshold = 0 } = {
        // Default value on empty constructor
        copy: true,
        threshold: 0
    }) {
        this.threshold = threshold;
        this.copy = copy;
    }
    /**
     * Currently fit does nothing
     * @param {any[]} X - Does nothing
     */
    fit(X = null) {
        if (Array.isArray(X) && X.length === 0) {
            throw new TypeError('X cannot be empty');
        }
        validateMatrix2D(X);
        console.info("Currently Bianrizer's fit is designed to do nothing");
    }
    /**
     * Transforms matrix into binarized form
     * X = [[ 1., -1.,  2.],
     *      [ 2.,  0.,  0.],
     *      [ 0.,  1., -1.]]
     * becomes
     * array([[ 1.,  0.,  1.],
     *    [ 1.,  0.,  0.],
     *    [ 0.,  1.,  0.]])
     * @param {any[]} X - The data to binarize.
     */
    transform(X = null) {
        const _X = this.copy ? _.clone(X) : X;
        if (Array.isArray(_X) && _X.length === 0) {
            throw new TypeError('X cannot be empty');
        }
        validateMatrix2D(_X);
        for (let row = 0; row < _.size(X); row++) {
            const rowValue = _.get(X, `[${row}]`);
            for (let column = 0; column < _.size(rowValue); column++) {
                const item = _.get(X, `[${row}][${column}]`);
                // Type checking item; It must be a number type
                if (!_.isNumber(item)) {
                    throw new Error(`Value ${item} is not a number`);
                }
                // If current item is less than
                _X[row][column] = item <= this.threshold ? 0 : 1;
            }
        }
        return _X;
    }
}
/**
 * Generate polynomial and interaction features.
 *
 * Generate a new feature matrix consisting of all polynomial combinations of the features
 * with degree less than or equal to the specified degree. For example, if an input sample
 * is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].
 *
 * @example
 * import { PolynomialFeatures } from 'machinelearn/preprocessing';
 * const poly = new PolynomialFeatures();
 * const X = [[0, 1], [2, 3], [4, 5]];
 * poly.transform(X);
 * // Result:
 * // [ [ 1, 0, 1, 0, 0, 1 ],
 * // [ 1, 2, 3, 4, 6, 9 ],
 * // [ 1, 4, 5, 16, 20, 25 ] ]
 *
 */
export class PolynomialFeatures {
    /**
     *
     * @param degree - The degree of the polynomial features. Default = 2.
     */
    constructor({ degree = 2 } = {
        degree: 2
    }) {
        // Constructor variables validation
        if (!Number.isInteger(degree)) {
            throw new Error('Degree must be a number');
        }
        this.degree = degree;
    }
    /**
     * Transforms the input data
     * @param X - a matrix
     */
    transform(X = null) {
        if (Array.isArray(X) && X.length === 0) {
            throw new TypeError('X cannot be empty');
        }
        validateMatrix2D(X);
        const matrix = tf.tensor2d(X);
        const [nSamples, nFeatures] = matrix.shape;
        const indexCombination = this.indexCombination(nFeatures, this.degree);
        const nOutputFeatures = indexCombination.length;
        // Polynomial feature extraction loop begins
        const tfOnes = tf.ones([nSamples, nOutputFeatures]);
        let result = reshape(Array.from(tfOnes.dataSync()), tfOnes.shape);
        const rowRange = _.range(0, X.length);
        for (let i = 0; i < indexCombination.length; i++) {
            const c = indexCombination[i];
            const colsRange = Array.isArray(c) ? c : [c];
            // Retrieves column values from X using the index of the indexCombination in the loop
            const srcColValues = c !== null ? math.subset(X, rowRange, colsRange) : [];
            let xc = null;
            if (srcColValues.length === 0) {
                xc = _.fill(rowRange.slice(), 1);
            }
            else {
                xc = tf
                    .tensor2d(srcColValues)
                    .prod(1)
                    .dataSync();
            }
            result = math.subset(result, rowRange, [i], xc);
        }
        return result;
    }
    /**
     * Creates a combination of index according to nFeautres and degree
     * @param nFeatures
     * @param degree
     */
    indexCombination(nFeatures, degree) {
        const range = _.range(0, degree + 1);
        const combs = range.map(i => {
            return combinationsWithReplacement(_.range(nFeatures), i);
        });
        return combs.reduce((sum, cur) => {
            return sum.concat(cur);
        }, []);
    }
}
/**
 * Data normalization is a process of scaling dataset based on Vector Space Model, and by default, it uses L2 normalization.
 * At a higher level, the chief difference between the L1 and the L2 terms is that the L2 term is proportional
 * to the square of the  β values, while the L1 norm is proportional the absolute value of the values in  β .
 *
 * @example
 * import { normalize } from 'machinelearn/preprocessing';
 *
 * const result = normalize([
 *   [1, -1, 2],
 *   [2, 0, 0],
 *   [0, 1, -1],
 * ], { norm: 'l2' });
 * console.log(result);
 * // [ [ 0.4082482904638631, -0.4082482904638631, 0.8164965809277261 ],
 * // [ 1, 0, 0 ],
 * // [ 0, 0.7071067811865475, -0.7071067811865475 ] ]
 *
 * @param X - The data to normalize
 * @param norm - The norm to use to normalize each non zero sample; can be either 'l1' or 'l2'
 * @return number[][]
 */
export function normalize(X = null, { norm = 'l2' } = {
    norm: 'l2'
}) {
    if (Array.isArray(X) && X.length === 0) {
        throw new TypeError('X cannot be empty');
    }
    validateMatrix2D(X);
    const normalizedMatrix = [];
    for (let i = 0; i < X.length; i++) {
        const row = X[i];
        // Adding a placeholder array
        normalizedMatrix.push([]);
        // Getting the row's square root
        let proportion = 0; // note: any because math.pow return MathType
        // Normalization proportion value
        if (norm === 'l1') {
            proportion = row.reduce((accum, r) => accum + Math.abs(r), 0);
        }
        else if (norm === 'l2') {
            proportion = row.reduce((accum, r) => accum + Math.pow(r, 2), 0);
            proportion = Math.sqrt(proportion);
        }
        else {
            throw new Error(`${norm} is not a recognised normalization method`);
        }
        // Finally applying a cubic root to the total value
        for (let k = 0; k < row.length; k++) {
            const value = row[k] / proportion;
            normalizedMatrix[i].push(value);
        }
    }
    return normalizedMatrix;
}
//# sourceMappingURL=data:application/json;base64,{"version":3,"file":"data.js","sourceRoot":"","sources":["../../../../../src/lib/preprocessing/data.ts"],"names":[],"mappings":"AAAA,OAAO,KAAK,EAAE,MAAM,kBAAkB,CAAC;AACvC,OAAO,KAAK,CAAC,MAAM,QAAQ,CAAC;AAC5B,OAAO,EACL,UAAU,EACV,OAAO,EACP,gBAAgB,EAChB,gBAAgB,EACjB,MAAM,QAAQ,CAAC;AAEhB,OAAO,IAAI,MAAM,oBAAoB,CAAC;AACtC,OAAO,EAAE,2BAA2B,EAAE,MAAM,uBAAuB,CAAC;AAoCpE;;;;;;;;;;;GAWG;AACH,MAAM,4BACJ,IAA0B,IAAI,EAC9B,QAAgB,GAAG;IAEnB,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;QACtC,MAAM,IAAI,SAAS,CAAC,mBAAmB,CAAC,CAAC;KAC1C;IACD,gBAAgB,CAAC,CAAC,CAAC,CAAC;IACpB,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAc,CAAC;IAC5C,MAAM,CAAC,QAAQ,CAAC,GAAG,OAAO,CAAC,KAAK,CAAC;IACjC,MAAM,IAAI,GAAG,EAAE,CAAC,IAAI,CAAC,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAc,CAAC;IACjD,MAAM,MAAM,GAAG,EAAE,CAAC,MAAM,CAAC,KAAK,CAAc,CAAC;IAC7C,MAAM,aAAa,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,EAAE,MAAM,CAAC,CAAC;IAC3C,MAAM,QAAQ,GAAG,EAAE,CAAC,MAAM,CAAC,CAAC,aAAa,EAAE,OAAO,CAAC,EAAE,CAAC,CAAC,CAAC;IACxD,OAAO,OAAO,CAAC,KAAK,CAAC,IAAI,CAAC,QAAQ,CAAC,QAAQ,EAAE,CAAC,EAAE,QAAQ,CAAC,KAAK,CAAe,CAAC;AAChF,CAAC;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;GA2BG;AACH,MAAM;IAAN;QA2LE;;;;;WAKG;QACK,iBAAY,GAAG,CAAC,GAAG,EAAE,IAAY,EAAE,EAAE;YAC3C,MAAM,UAAU,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,CAAS,EAAE,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,EAAE,CAAC,CAAC,CAAC,CAAC;YACpE,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,UAAU,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,GAAG,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC;QAC7D,CAAC,CAAC;IA4EJ,CAAC;IA/QC;;;;;OAKG;IACI,MAAM,CACX,IAAI,GAAG,IAAI,EACX;IACE;;OAEG;IACH,QAAQ,GAAG,IAAI;IACf;;OAEG;IACH,SAAS,GAAG,IAAI,KAId;QACF,QAAQ,EAAE,IAAI;QACd,SAAS,EAAE,IAAI;KAChB;QAWD,MAAM,QAAQ,GAAG,EAAE,CAAC;QAEpB,4EAA4E;QAC5E,MAAM,SAAS,GAAG,QAAQ,CAAC,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;QACxD,cAAc;QACd,IAAI,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE;YACpB,MAAM,KAAK,CAAC,uBAAuB,CAAC,CAAC;SACtC;QACD,YAAY;QACZ,CAAC,CAAC,OAAO,CAAC,SAAS,EAAE,OAAO,CAAC,EAAE;YAC7B,0EAA0E;YAC1E,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,EAAE;gBAC5B,wCAAwC;gBACxC,MAAM,KAAK,CAAC,eAAe,OAAO,YAAY,CAAC,CAAC;aACjD;QACH,CAAC,CAAC,CAAC;QAEH,aAAa;QACb,CAAC,CAAC,OAAO,CAAC,SAAS,EAAE,QAAQ,CAAC,EAAE;YAC9B,0EAA0E;YAC1E,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,EAAE;gBAC7B,uCAAuC;gBACvC,MAAM,KAAK,CAAC,eAAe,QAAQ,cAAc,CAAC,CAAC;aACpD;QACH,CAAC,CAAC,CAAC;QAEH,mDAAmD;QACnD,0GAA0G;QAC1G,MAAM,SAAS,GAAG,CAAC,IAA0B,EAAE,EAAE,CAC/C,CAAC,CAAC,GAAG,CACH,GAAG,CAAC,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,GAAW,EAAE,EAAE;YAC7B,MAAM,YAAY,GAAG,IAAI,CAAC,gBAAgB,CAAC,GAAG,EAAE,IAAI,CAAC,CAAC;YACtD,MAAM,OAAO,GAAG,CAAC,CAAC,GAAG,CAAC,YAAY,EAAE,SAAS,CAAC,CAAC;YAC/C,MAAM,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC,YAAY,EAAE,QAAQ,CAAC,CAAC;YAC7C,IAAI,OAAO,IAAI,MAAM,EAAE;gBACrB,kDAAkD;gBAClD,QAAQ,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;gBACtB,OAAO,OAAO,CAAC;aAChB;YACD,sCAAsC;YACtC,OAAO,YAAY,CAAC;QACtB,CAAC,CAAC,CACH,CAAC;QACJ,MAAM,QAAQ,GAAG,SAAS,CAAC,SAAS,CAAC,CAAC;QACtC,MAAM,MAAM,GAAG,SAAS,CAAC,SAAS,CAAC,CAAC;QACpC,OAAO;YACL,qFAAqF;YACrF,IAAI,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,QAAQ,EAAE,MAAM,CAAC,EAAE,CAAC,CAAC,WAAW,CAAC;YACnD,QAAQ;SACT,CAAC;IACJ,CAAC;IAED;;OAEG;IACI,MAAM,CAAC,OAAO,EAAE,QAAQ;QAC7B,OAAO,CAAC,CAAC,GAAG,CAAC,OAAO,EAAE,GAAG,CAAC,EAAE,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,EAAE,QAAQ,CAAC,CAAC,CAAC;IAC9D,CAAC;IAED;;;;;OAKG;IACK,SAAS,CAAC,GAAG,EAAE,QAAQ;QAC7B,IAAI,CAAC,GAAG,CAAC,CAAC;QACV,IAAI,gBAAgB,GAAG,CAAC,CAAC;QACzB,MAAM,MAAM,GAAG,EAAE,CAAC;QAElB,MAAM,SAAS,GAAG,CAAC,CAAC,EAAE,EAAE,EAAE,OAAO,EAAU,EAAE;YAC3C,MAAM,IAAI,GAAG,CAAC,CAAC,KAAK,CAAC,EAAE,EAAE,EAAE,GAAG,OAAO,CAAC,MAAM,CAAC,CAAC;YAC9C,OAAO,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,CAAC,CAAC;QAEF,MAAM,UAAU,GAAG,CAAC,CAAC,EAAE,EAAE,EAAW,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;QAE/C,MAAM,UAAU,GAAG,CAAC,CAAC,EAAE,EAAE,EAAE,OAAO,EAAU,EAAE;YAC5C,OAAO,OAAO,CAAC,GAAG,GAAG,CAAC,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,IAAI,CAAC;QAC5C,CAAC,CAAC;QAEF,OAAO,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE;YACrB,MAAM,OAAO,GAAG,QAAQ,CAAC,gBAAgB,EAAE,CAAC,CAAC;YAC7C,IAAI,OAAO,CAAC,IAAI,KAAK,QAAQ,EAAE;gBAC7B,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,SAAS,CAAC,GAAG,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC;aAClD;iBAAM,IAAI,OAAO,CAAC,IAAI,KAAK,QAAQ,EAAE;gBACpC,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,UAAU,CAAC,GAAG,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC;aACnD;iBAAM,IAAI,OAAO,CAAC,IAAI,KAAK,SAAS,EAAE;gBACrC,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,UAAU,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC;aAC1C;iBAAM;gBACL,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC;aAC9B;YACD,mDAAmD;YACnD,CAAC,IAAI,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;SAC1C;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED;;;;;;;;;;OAUG;IACK,gBAAgB,CACtB,GAAG,EACH,IAAI;QAEJ,MAAM,IAAI,GAAG,OAAO,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QACjC,MAAM,MAAM,GAAG,CAAC,CAAC,GAAG,CAAC,IAAI,EAAE,GAAG,CAAC,CAAC;QAChC,QAAQ,IAAI,EAAE;YACZ,KAAK,QAAQ,CAAC,CAAC;gBACb,MAAM,MAAM,GAAG,IAAI,CAAC,iBAAiB,CAAC,IAAI,EAAE,GAAG,EAAE,MAAM,CAAC,CAAC;gBACzD,OAAO;oBACL,MAAM,EAAE,MAAM,CAAC,MAAM;oBACrB,OAAO,EAAE,MAAM,CAAC,OAAO;iBACxB,CAAC;aACH;YAED,KAAK,QAAQ,CAAC,CAAC;gBACb,wCAAwC;gBACxC,gCAAgC;gBAChC,0CAA0C;gBAC1C,MAAM,MAAM,GAAG,IAAI,CAAC,iBAAiB,CAAC,IAAI,EAAE,GAAG,EAAE,MAAM,CAAC,CAAC;gBAEzD,OAAO;oBACL,MAAM,EAAE,MAAM,CAAC,MAAM;oBACrB,OAAO,EAAE,MAAM,CAAC,OAAO;iBACxB,CAAC;aACH;YAED,KAAK,SAAS,CAAC,CAAC;gBACd,YAAY;gBACZ,aAAa;gBACb,MAAM,MAAM,GAAG,IAAI,CAAC,kBAAkB,CAAC,IAAI,EAAE,GAAG,EAAE,MAAM,CAAC,CAAC;gBAE1D,OAAO;oBACL,MAAM,EAAE,MAAM,CAAC,MAAM;oBACrB,OAAO,EAAE,MAAM,CAAC,OAAO;iBACxB,CAAC;aACH;YAED;gBACE,OAAO,MAAM,CAAC;SACjB;IACH,CAAC;IAaD;;;;;;;OAOG;IACK,iBAAiB,CAAC,IAAI,EAAE,GAAG,EAAE,MAAM;QACzC,MAAM,IAAI,GAAW,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;QACpC,MAAM,GAAG,GAAG,IAAI,CAAC,YAAY,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;QAC5C,OAAO;YACL,MAAM,EAAE,EAAE,IAAI,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE;YAChC,OAAO,EAAE,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,KAAa,EAAE,EAAE,CAAC,CAAC,KAAK,GAAG,IAAI,CAAC,GAAG,GAAG,CAAC;SAChE,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;OAWG;IACK,kBAAkB,CAAC,IAAI,EAAE,GAAG,EAAE,MAAM;QAC1C,OAAO;YACL,MAAM,EAAE,EAAE,IAAI,EAAE,GAAG,EAAE;YACrB,OAAO,EAAE,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,KAAK,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;SACjD,CAAC;IACJ,CAAC;IAED;;;;;;;;;;;;;;OAcG;IACK,iBAAiB,CAAC,IAAI,EAAE,GAAG,EAAE,MAAM;QACzC,MAAM,MAAM,GAAG,EAAE,CAAC;QAClB,IAAI,CAAC,GAAG,CAAC,CAAC;QAEV,MAAM,WAAW,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,KAAa,EAAE,EAAE;YAC1D,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,KAAK,EAAE,CAAC,EAAE,CAAC,CAAC;YAC1B,OAAO,KAAK,CAAC;QACf,CAAC,CAAC,CAAC;QAEH,MAAM,OAAO,GAAG,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,KAAa,EAAE,EAAE,CAC9C,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CACjE,CAAC;QAEF,OAAO;YACL,MAAM,EAAE;gBACN,GAAG;gBACH,WAAW;gBACX,MAAM,EAAE,OAAO,CAAC,CAAC,CAAC,CAAC,MAAM;gBACzB,IAAI;aACL;YACD,OAAO;SACR,CAAC;IACJ,CAAC;CACF;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GAgCG;AACH,MAAM;IAUJ;;OAEG;IACH,YACE,EACE,YAAY,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,KAGnB;QACF,YAAY,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;KACrB;QAED,IAAI,CAAC,YAAY,GAAG,YAAY,CAAC;IACnC,CAAC;IAED;;;OAGG;IACI,GAAG,CAAC,IAAiD,IAAI;QAC9D,IAAI,MAAM,GAAG,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;QAC1B,IAAI,MAAM,GAAG,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;QAC1B,MAAM,MAAM,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAC7B,0BAA0B;QAC1B,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,IAAI,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,EAAE;YAC1C,MAAM,IAAI,SAAS,CAAC,gCAAgC,CAAC,CAAC;SACvD;aAAM,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;YAC9B,MAAM,GAAG,EAAE,CAAC,GAAG,CAAC,MAAmB,EAAE,CAAC,CAAC,CAAC;YACxC,MAAM,GAAG,EAAE,CAAC,GAAG,CAAC,MAAmB,EAAE,CAAC,CAAC,CAAC;SACzC;QACD,IAAI,CAAC,OAAO,GAAG,EAAE,CAAC,GAAG,CAAC,MAAmB,CAAC,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,IAAI,CAAC,OAAO,GAAG,EAAE,CAAC,GAAG,CAAC,MAAmB,CAAC,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;QACvC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;QACvC,oCAAoC;QACpC,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC;QAC7C,qDAAqD;QACrD,IAAI,CAAC,KAAK,GAAG,CAAC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC,GAAG,IAAI,CAAC,SAAS,CAAC;QAClE,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,KAAK,CAAC;IAC7D,CAAC;IAED;;;OAGG;IACI,aAAa,CAClB,CAA8C;QAE9C,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACZ,OAAO,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC;IAC3B,CAAC;IAED;;;OAGG;IACI,SAAS,CACd,IAAiD,IAAI;QAErD,6BAA6B;QAC7B,MAAM,gBAAgB,GAAG,EAAE,CAAC,EAAE;YAC5B,MAAM,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC;YACvC,OAAO,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC;QACvC,CAAC,CAAC;QACF,MAAM,MAAM,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAC7B,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;YACvB,OAAQ,CAAgB,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC;SACxD;aAAM,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;YAC9B,OAAO,gBAAgB,CAAC,CAAC,CAAC,CAAC;SAC5B;aAAM;YACL,MAAM,IAAI,SAAS,CACjB,mBAAmB,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,wBAAwB,CAClE,CAAC;SACH;IACH,CAAC;IAED;;;OAGG;IACI,iBAAiB,CAAC,IAA0B,IAAI;QACrD,gBAAgB,CAAC,CAAC,CAAC,CAAC;QACpB,MAAM,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC;QACxC,OAAO,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC;IACrC,CAAC;CACF;AAED;;;;;;;;;;;;;;;GAeG;AACH,MAAM;IAIJ;;;;OAIG;IACH,YACE;IACE,kCAAkC;IAClC,IAAI,GAAG,IAAI,EACX,SAAS,GAAG,CAAC,KAKX;QACF,qCAAqC;QACrC,IAAI,EAAE,IAAI;QACV,SAAS,EAAE,CAAC;KACb;QAED,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC;QAC3B,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;IACnB,CAAC;IAED;;;OAGG;IACI,GAAG,CAAC,IAA0B,IAAI;QACvC,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;YACtC,MAAM,IAAI,SAAS,CAAC,mBAAmB,CAAC,CAAC;SAC1C;QACD,gBAAgB,CAAC,CAAC,CAAC,CAAC;QACpB,OAAO,CAAC,IAAI,CAAC,qDAAqD,CAAC,CAAC;IACtE,CAAC;IAED;;;;;;;;;;OAUG;IACI,SAAS,CAAC,IAA0B,IAAI;QAC7C,MAAM,EAAE,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtC,IAAI,KAAK,CAAC,OAAO,CAAC,EAAE,CAAC,IAAI,EAAE,CAAC,MAAM,KAAK,CAAC,EAAE;YACxC,MAAM,IAAI,SAAS,CAAC,mBAAmB,CAAC,CAAC;SAC1C;QACD,gBAAgB,CAAC,EAAE,CAAC,CAAC;QACrB,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,GAAG,EAAE,EAAE;YACxC,MAAM,QAAQ,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,GAAG,GAAG,CAAC,CAAC;YACtC,KAAK,IAAI,MAAM,GAAG,CAAC,EAAE,MAAM,GAAG,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,EAAE,MAAM,EAAE,EAAE;gBACxD,MAAM,IAAI,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,GAAG,KAAK,MAAM,GAAG,CAAC,CAAC;gBAC7C,+CAA+C;gBAC/C,IAAI,CAAC,CAAC,CAAC,QAAQ,CAAC,IAAI,CAAC,EAAE;oBACrB,MAAM,IAAI,KAAK,CAAC,SAAS,IAAI,kBAAkB,CAAC,CAAC;iBAClD;gBACD,+BAA+B;gBAC/B,EAAE,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC,GAAG,IAAI,IAAI,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;aAClD;SACF;QACD,OAAO,EAAE,CAAC;IACZ,CAAC;CACF;AAED;;;;;;;;;;;;;;;;;GAiBG;AACH,MAAM;IAGJ;;;OAGG;IACH,YACE,EACE,MAAM,GAAG,CAAC,KAGR;QACF,MAAM,EAAE,CAAC;KACV;QAED,mCAAmC;QACnC,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,EAAE;YAC7B,MAAM,IAAI,KAAK,CAAC,yBAAyB,CAAC,CAAC;SAC5C;QACD,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;IACvB,CAAC;IAED;;;OAGG;IACI,SAAS,CAAC,IAA0B,IAAI;QAC7C,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;YACtC,MAAM,IAAI,SAAS,CAAC,mBAAmB,CAAC,CAAC;SAC1C;QACD,gBAAgB,CAAC,CAAC,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC;QAC9B,MAAM,CAAC,QAAQ,EAAE,SAAS,CAAC,GAAG,MAAM,CAAC,KAAK,CAAC;QAC3C,MAAM,gBAAgB,GAAG,IAAI,CAAC,gBAAgB,CAAC,SAAS,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;QACvE,MAAM,eAAe,GAAG,gBAAgB,CAAC,MAAM,CAAC;QAEhD,4CAA4C;QAC5C,MAAM,MAAM,GAAG,EAAE,CAAC,IAAI,CAAC,CAAC,QAAQ,EAAE,eAAe,CAAC,CAAC,CAAC;QACpD,IAAI,MAAM,GAAG,OAAO,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAC,EAAE,MAAM,CAAC,KAAK,CAAC,CAAC;QAClE,MAAM,QAAQ,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,MAAM,CAAC,CAAC;QACtC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,gBAAgB,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YAChD,MAAM,CAAC,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC;YAC9B,MAAM,SAAS,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YAC7C,qFAAqF;YACrF,MAAM,YAAY,GAChB,CAAC,KAAK,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC;YACxD,IAAI,EAAE,GAAG,IAAI,CAAC;YACd,IAAI,YAAY,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC7B,EAAE,GAAG,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC,CAAC;aAClC;iBAAM;gBACL,EAAE,GAAG,EAAE;qBACJ,QAAQ,CAAC,YAAY,CAAC;qBACtB,IAAI,CAAC,CAAC,CAAC;qBACP,QAAQ,EAAE,CAAC;aACf;YACD,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,QAAQ,EAAE,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;SACjD;QACD,OAAO,MAAoB,CAAC;IAC9B,CAAC;IAED;;;;OAIG;IACK,gBAAgB,CAAC,SAAS,EAAE,MAAM;QACxC,MAAM,KAAK,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,MAAM,GAAG,CAAC,CAAC,CAAC;QACrC,MAAM,KAAK,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE;YAC1B,OAAO,2BAA2B,CAAC,CAAC,CAAC,KAAK,CAAC,SAAS,CAAC,EAAE,CAAC,CAAC,CAAC;QAC5D,CAAC,CAAC,CAAC;QACH,OAAO,KAAK,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,EAAE;YAC/B,OAAO,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACzB,CAAC,EAAE,EAAE,CAAC,CAAC;IACT,CAAC;CACF;AAED;;;;;;;;;;;;;;;;;;;;;GAqBG;AACH,MAAM,oBACJ,IAA0B,IAAI,EAC9B,EACE,IAAI,GAAG,IAAI,KAGT;IACF,IAAI,EAAE,IAAI;CACX;IAED,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;QACtC,MAAM,IAAI,SAAS,CAAC,mBAAmB,CAAC,CAAC;KAC1C;IACD,gBAAgB,CAAC,CAAC,CAAC,CAAC;IACpB,MAAM,gBAAgB,GAAG,EAAE,CAAC;IAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;QACjC,MAAM,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;QAEjB,6BAA6B;QAC7B,gBAAgB,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;QAE1B,gCAAgC;QAChC,IAAI,UAAU,GAAQ,CAAC,CAAC,CAAC,6CAA6C;QAEtE,iCAAiC;QACjC,IAAI,IAAI,KAAK,IAAI,EAAE;YACjB,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,KAAU,EAAE,CAAC,EAAE,EAAE,CAAC,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;SACpE;aAAM,IAAI,IAAI,KAAK,IAAI,EAAE;YACxB,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,KAAU,EAAE,CAAC,EAAE,EAAE,CAAC,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;YACtE,UAAU,GAAG,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;SACpC;aAAM;YACL,MAAM,IAAI,KAAK,CAAC,GAAG,IAAI,2CAA2C,CAAC,CAAC;SACrE;QAED,mDAAmD;QACnD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACnC,MAAM,KAAK,GAAG,GAAG,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC;YAClC,gBAAgB,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SACjC;KACF;IACD,OAAO,gBAAgB,CAAC;AAC1B,CAAC"}